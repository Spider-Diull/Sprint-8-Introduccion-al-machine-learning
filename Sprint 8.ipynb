{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de contenido<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduccion\" data-toc-modified-id=\"Introduccion-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduccion</a></span></li><li><span><a href=\"#Paso-a-paso-del-proyecto\" data-toc-modified-id=\"Paso-a-paso-del-proyecto-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Paso a paso del proyecto</a></span><ul class=\"toc-item\"><li><span><a href=\"#Librerias-necesarias-para-el-proyecto.\" data-toc-modified-id=\"Librerias-necesarias-para-el-proyecto.-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Librerias necesarias para el proyecto.</a></span></li><li><span><a href=\"#Lectura-del-dataset.\" data-toc-modified-id=\"Lectura-del-dataset.-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Lectura del dataset.</a></span></li><li><span><a href=\"#--Segmentamos-los-datos-en-conjuntos-para-el-modelo.\" data-toc-modified-id=\"--Segmentamos-los-datos-en-conjuntos-para-el-modelo.-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>- Segmentamos los datos en conjuntos para el modelo.</a></span></li><li><span><a href=\"#Calidad-y-pruebas-del-modelo.\" data-toc-modified-id=\"Calidad-y-pruebas-del-modelo.-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Calidad y pruebas del modelo.</a></span></li></ul></li><li><span><a href=\"#Conclusiones.\" data-toc-modified-id=\"Conclusiones.-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Conclusiones.</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduccion\n",
    "\n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "Nos acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos. Para esta tarea de clasificación vamos a crear un modelo que escoja el plan correcto. Sabemos que los datos ya fueron procesados previamente por lo que nos iremos directo a crear el modelo.\n",
    "\n",
    "Desarrollaremos un modelo con la mayor exactitud posible. En este proyecto, el umbral de\n",
    "exactitud es 0.75. Usaremos el dataset para comprobar la exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso a paso del proyecto\n",
    "\n",
    "### Librerias necesarias para el proyecto.\n",
    "\n",
    "- Importamos las librerias que utlizaremos en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura del dataset.\n",
    "- Leemos el dataset que utilizaremos en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_megaline=pandas.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comprobamos los datos del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informacion del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "print('Informacion del dataset:')\n",
    "df_megaline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripcion del dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Descripcion del dataset.')\n",
    "df_megaline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprobamos los datos duplicados en el dataset.\n",
      "El dataset tiene 0 duplicados.\n"
     ]
    }
   ],
   "source": [
    "print('Comprobamos los datos duplicados en el dataset.')\n",
    "print('El dataset tiene',df_megaline.duplicated().sum(),'duplicados.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprobamos si hay datos nulos.\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Comprobamos si hay datos nulos.')\n",
    "print(df_megaline.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segun lo visto el dataset no tiene datos duplicados y tampoco tien datos nulos por lo que efectivamente esta procesado, por lo que podemos continuar con el proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Segmentamos los datos en conjuntos para el modelo.\n",
    "\n",
    "- Dividimos el dataset en 3 conjuntos, uno de entrenamientos, validacion y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manera aprendida en el sprint 8 que divide en 2 conjuntos con proporcion 3:1.\n",
    "# megaline_train,megaline_valid= train_test_split(df_megaline,test_size=0.2,random_state=54321)\n",
    "\n",
    "# Manera investigada para dividir en 3 conjuntos con proporcion 3:1:1.\n",
    "\n",
    "# Obtenemos el conjunto de 'test' y dejamos otro conjunto llamado 'rest'.\n",
    "megaline_rest,megaline_test=train_test_split(df_megaline,test_size=0.2,random_state=54321)\n",
    "\n",
    "# Del conjunto 'rest' obtendemos el conjunto de entrenamiento y validacion.\n",
    "megaline_train,megaline_valid=train_test_split(megaline_rest,test_size=0.25,random_state=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teniendo los conjuntos de entrenamiento,validacion y prueba, separamos cada uno en las caracteristicas y el objetivo para nuestro modelo con una proporcion de 3:1:1  (un 60 % para el conjunto de entrenamiento y un 20 % para los conjuntos de validación y prueba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento\n",
    "features_train=megaline_train.drop(['is_ultra'],axis=1)\n",
    "target_train=megaline_train['is_ultra']\n",
    "#Validacion\n",
    "features_valid=megaline_valid.drop(['is_ultra'],axis=1)\n",
    "target_valid= megaline_valid['is_ultra']\n",
    "#Prueba\n",
    "features_test=megaline_test.drop(['is_ultra'],axis=1)\n",
    "target_test=megaline_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calidad y pruebas del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comenzamos con la creacion del modelo, en este caso eligimos el modelo de bosque aleatorio (RandomForestClassifier), aprovechando la creacion del bosque aleatorio realizaremos los preparativos para las pruebas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaramos variables para medir mce y exactitud de los modelos.\n",
    "best_score=0\n",
    "best_est_score=0\n",
    "best_est_mse=0\n",
    "best_depth=0\n",
    "best_mse=0\n",
    "for est in range(5,20,5): # Entrenaremos 20 modelos en intervalos de 5\n",
    "    for depth in range (1,5): # La profundidad de los arboles sera de 1 a 5\n",
    "        model_megaline=RandomForestClassifier(random_state=54321,n_estimators=est, max_depth=depth) # Configuramos el numero de arboles.\n",
    "        model_megaline.fit(features_train,target_train) # Entrenamos el modelo con el conjunto de entrenamiento.\n",
    "        predictions_valid= model_megaline.predict(features_valid) # Realizamos prediciones con el conjunto de validación.\n",
    "        mse=mean_squared_error(target_valid,predictions_valid)**0.5 # Calculamos el ECM\n",
    "        score= model_megaline.score(features_test,target_test) # Calculamos la puntuacion de accuracy en el conjunto de test.\n",
    "        if score>best_score:\n",
    "            best_score=score # Guardamos la mejor puntuacion de accurracy en el conjunto de validación.\n",
    "            best_est_score=est # Guardamos el número de estimadores que corresponden a la mejor punturación de exactitud.\n",
    "        if mse>best_mse:\n",
    "            best_mse=mse # Guardamos la mejor prueba de MCE.\n",
    "            best_est_mse=est # Guardamos el número de estimadores que corresponden a la mejor prueba de MCE.\n",
    "            best_depth= depth # Guardamos la mejor profundidad para los arboles del bosque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Solo nos queda mostrar las metricas conseguidas en las pruebas del modelo con bosque aleatorio, comenzamos por el RECM (raíz del error cuadrático medio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El RECM del mejor modelo en el conjunto de validación: 0.4797614752091583 con estimadores de: 15 y mejor profundidad: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"El RECM del mejor modelo en el conjunto de validación:\", best_mse, \"con estimadores de:\", best_est_mse, \"y mejor profundidad:\", best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostramos la exactitud del mejor modelo del bosque aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de pruebas con n_estimators(estimadores) 15) es de : 0.7776049766718507\n"
     ]
    }
   ],
   "source": [
    "print(\"La exactitud del mejor modelo en el conjunto de pruebas con n_estimators(estimadores) {}) es de : {}\".format(best_est_score, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Probaremos con otro modelo, utilizaremos el modelo árbol de decisión(DecisionTreeRegressor), aprovechando la creacion del arbol realizaremos los preparativos para las pruebas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaramos variables para medir mce y exactitud de los modelos.\n",
    "best_score=0\n",
    "best_depth=0\n",
    "best_mse=0\n",
    "for depth in range(1,6): # Seleccionamos el rango del hiperparámetro.\n",
    "    model_megaline= DecisionTreeClassifier(max_depth=depth,random_state=12345) # Declaramos el modelo.\n",
    "    model_megaline.fit(features_train,target_train) # Entrenamos el modelo en el conjunto de entrenamiento.\n",
    "    predictions_valid = model_megaline.predict(features_valid) # Obtenemos las predicciones del modelo en el conjunto de validación.\n",
    "    mse =mean_squared_error(target_valid,predictions_valid)**0.5# calcula la RECM en el conjunto de validación\n",
    "    score= model_megaline.score(features_test,target_test) # Calculamos la puntuacion de accuracy en el conjunto de test.\n",
    "    if mse > best_mse:\n",
    "        best_mse = mse\n",
    "        best_depth = depth\n",
    "    if score>best_score:\n",
    "        best_score=score # Guardamos la mejor puntuacion de accurracy en el conjunto de validación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Solo nos queda mostrar las metricas conseguidas en las pruebas del modelo con bosque aleatorio, comenzamos por el RECM (raíz del error cuadrático medio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El RECM del mejor modelo en el conjunto de validación: 0.4732338040350594 y mejor profundidad: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"El RECM del mejor modelo en el conjunto de validación:\", best_mse,\"y mejor profundidad:\", best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostramos la exactitud del mejor modelo del arbol de decisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de pruebas es de : 0.7682737169517885\n"
     ]
    }
   ],
   "source": [
    "print(\"La exactitud del mejor modelo en el conjunto de pruebas es de : {}\".format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fue un desafio el crear 3 conjuntos ya que durante el sprint fuimos realizando practicas solo creando conjuntos de entrenamiento y validacion, al crear 3 conjuntos fue mas sencillo saber cuales utilizariamos para entrenar el modelo(conjunto de entrenamiento), medir la exactitud del modelo(conjunto de validación) y la métrica de evaluación de error cuadrático medio o ECM(conjunto de prueba). Si gusta puedo dejar la fuente de donde aprendi a realizar los 3 conjuntos con proporcion 3:1:1.\n",
    "\n",
    "Decidi utilizar en este caso el  algoritmo de aprendizaje bosque aleatorio por que entrena una gran cantidad de árboles independientes y toma una decisión mediante el voto ya que con un bosque aleatorio obtenemos mejores resultados y a evitamos el sobreajuste.\n",
    "\n",
    "Gracias a esto sabemos que el mejor modelo contempla:\n",
    "\n",
    "- 15 estimadores\n",
    "- Una profunidad maxima de 1\n",
    "- Un RECM de 0.48(0.4797614752091583)\n",
    "- Una exactitud de 0.77(0.7776049766718507)\n",
    "\n",
    "Se decidio probar con otro modelo, un modelo de árbol de decision, donde realizamos un proceso similar con el modelo del bosque aleatorio, conseguimos metricas bastante similares:\n",
    "\n",
    "- Una profunidad maxima de 1\n",
    "- Un RECM de 0.47(0.4732338040350594)\n",
    "- Una exactitud de 0.77(0.7682737169517885)\n",
    "\n",
    "Recordemos que el obejtivo del proyecto era desarrollar un modelo con la mayor exactitud posible. El umbral de exactitud del proyecto es 0.75 y con el mejor modelo conseguimos una exactitud que supera ese umbral aun que sea por poco. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de contenido",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
